# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zrw-m3Jt3MqcocECyaqTUnS7ri9gVDFg
"""

!pip install googletrans==4.0.0-rc1

"""Task One For Converting English text into French and Spanish"""

import googletrans
from googletrans import Translator

def translate_text(text, dest_language):
    translator = Translator()
    translation = translator.translate(text, dest=dest_language)
    return translation.text

def main():
    print("Simple Language Translation Tool")
    print("Supported languages: https://cloud.google.com/translate/docs/languages")
    text = input("Enter text to translate: ")
    target_lang = input("Enter target language code (e.g., 'fr' for French, 'es' for Spanish): ")

    try:
        translated_text = translate_text(text, target_lang)
        print(f"\nTranslated Text: {translated_text}")
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()



"""For Converting English text into Urdu"""

import googletrans
from googletrans import Translator

def translate_text(text, dest_language='ur'):
    translator = Translator()
    translation = translator.translate(text, dest=dest_language)
    return translation.text

def main():
    print("Simple Language Translation Tool (English to Urdu)")
    text = input("Enter text in English to translate to Urdu: ")

    try:
        translated_text = translate_text(text, 'ur')
        print(f"\nTranslated Text in Urdu: {translated_text}")
    except Exception as e:
        print(f"Error: {e}")

if __name__ == "__main__":
    main()

"""**Task two Chat Bot**

"""

import nltk
import numpy as np
import random
import string
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Sample FAQ data
faq_responses = {
    "What programs does the University of Education, Lahore offer?": "The University of Education, Lahore offers undergraduate, graduate, and postgraduate programs in various disciplines including education, sciences, and humanities.",
    "Where is the university located?": "The main campus of the University of Education is located in Lahore, Pakistan, with multiple sub-campuses across different cities.",
    "What are the admission requirements?": "Admission requirements vary by program. Generally, applicants need to meet minimum educational qualifications and pass an entry test or interview.",
    "Does the university offer scholarships?": "Yes, the university provides various merit-based and need-based scholarships for eligible students.",
    "Is hostel accommodation available?": "Yes, the University of Education, Lahore offers hostel facilities for students, subject to availability.",
    "How can I apply for admission?": "You can apply online through the official university website or visit the admission office for more details.",
    "What facilities does the university provide?": "The university offers modern classrooms, libraries, computer labs, research centers, and sports facilities for students.",
    "Does the university have an online learning system?": "Yes, the university provides an online learning system for distance education and e-learning programs."
}

# Preparing chatbot responses
faq_questions = list(faq_responses.keys())
nltk.download('punkt')
nltk.download('wordnet')

# Function to respond to user queries
def chatbot_response(user_input):
    user_input = user_input.lower()
    faq_questions.append(user_input)

    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(faq_questions)

    similarity_scores = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1])
    faq_questions.pop()

    index = np.argmax(similarity_scores)
    if similarity_scores[0][index] < 0.3:
        return "I'm sorry, I don't understand. Can you please rephrase?"
    else:
        return faq_responses[faq_questions[index]]

# Chatbot loop
def chat():
    print("Hello! I am your FAQ chatbot. Type 'exit' to end the conversation.")
    while True:
        user_input = input("You: ")
        if user_input.lower() == 'exit':
            print("Chatbot: Goodbye!")
            break
        response = chatbot_response(user_input)
        print(f"Chatbot: {response}")

if __name__ == "__main__":
    chat()

"""Music gerated **task**"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from music21 import converter, instrument, note, chord, stream
import glob

# Load and preprocess MIDI files
def load_midi_files(midi_path):
    notes = []
    for file in glob.glob(midi_path + "/*.mid"):
        midi = converter.parse(file)
        for part in midi.parts:
            for element in part.flat.notes:
                if isinstance(element, note.Note):
                    notes.append(str(element.pitch))
                elif isinstance(element, chord.Chord):
                    notes.append(".".join(str(n) for n in element.normalOrder))
    return notes

# Prepare sequences for training
def prepare_sequences(notes, seq_length=100):
    pitch_names = sorted(set(notes))
    note_to_int = {note: num for num, note in enumerate(pitch_names)}

    input_sequences, output_notes = [], []
    for i in range(len(notes) - seq_length):
        input_sequences.append([note_to_int[n] for n in notes[i:i + seq_length]])
        output_notes.append(note_to_int[notes[i + seq_length]])

    return np.array(input_sequences), np.array(output_notes), pitch_names

# Define LSTM model
def create_model(input_shape, num_classes):
    model = Sequential([
        LSTM(256, return_sequences=True, input_shape=input_shape),
        Dropout(0.3),
        LSTM(256),
        Dense(256, activation='relu'),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Generate new music
def generate_music(model, pitch_names, start_seq, length=500):
    int_to_note = {num: note for num, note in enumerate(pitch_names)}
    output = []
    pattern = start_seq

    for _ in range(length):
        input_seq = np.reshape(pattern, (1, len(pattern), 1))
        prediction = model.predict(input_seq, verbose=0)
        index = np.argmax(prediction)
        result = int_to_note[index]
        output.append(result)
        pattern.append(index)
        pattern = pattern[1:]

    return output

# Convert generated notes to MIDI
def create_midi(predicted_notes, output_file="generated_music.mid"):
    output_notes = []
    for note_str in predicted_notes:
        if '.' in note_str or note_str.isdigit():
            chord_notes = [note.Note(int(n)) for n in note_str.split('.')]
            new_chord = chord.Chord(chord_notes)
            output_notes.append(new_chord)
        else:
            new_note = note.Note(note_str)
            output_notes.append(new_note)

    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp=output_file)

# Example usage
if __name__ == "__main__":
    midi_path = "\Jazz Midi"  # Replace with your dataset path
    notes = load_midi_files(midi_path)
    input_sequences, output_notes, pitch_names = prepare_sequences(notes)
    input_shape = (input_sequences.shape[1], 1)
    num_classes = len(pitch_names)

    model = create_model(input_shape, num_classes)
    model.fit(input_sequences, tf.keras.utils.to_categorical(output_notes, num_classes), epochs=50, batch_size=64)

    start_seq = input_sequences[np.random.randint(0, len(input_sequences))].tolist()
    generated_notes = generate_music(model, pitch_names, start_seq)
    create_midi(generated_notes)